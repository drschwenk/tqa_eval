{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "from tqa_utils import Guesser\n",
    "from tqa_utils import Cheater\n",
    "from tqa_utils import Evaluator\n",
    "\n",
    "\n",
    "dataset_root_dir = '/Users/schwenk/wrk/stb/dataset_releases/data_release_beta6/'\n",
    "file_name = 'tqa_dataset_beta7_5.json'\n",
    "data_file =  dataset_root_dir + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('bad_student_results.json', 'w') as f:\n",
    "    json.dump(bad_student_answers, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_student = Guesser(data_file)\n",
    "cheating_student = Cheater(data_file)\n",
    "evaluator = Evaluator(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_student_answers = bad_student.make_predictions()\n",
    "# cheating_student_answers = cheating_student.make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Counter' object has no attribute 'total'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ab235df2050a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Counter' object has no attribute 'total'"
     ]
    }
   ],
   "source": [
    "Counter([3, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13.95'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0:.2f}\".format(13.949999999999999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_out = {'accuracy': {'diagramQuestions': 0.24858757062146894, 'nonDiagramQuestions': 0.33476959030161396, 'overall': 0.587052551408987}, 'total correct': Counter({'overall': 7708, 'nonDiagramQuestions': 4584, 'diagramQuestions': 3124})}\n",
    "test_out_tuples = {result_type: [[k, \"{0:.2f}\".format(v)] for k, v in sorted(result.items())] for result_type, result in test_out.items()}\n",
    "row_names = ['accuracy', 'total correct']\n",
    "column_names = [result[0] for result in test_out_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_results = defaultdict(list)\n",
    "for result_type, results in sorted(test_out.items()):\n",
    "    for q_type, result in results.items():\n",
    "        build_results[q_type].extend([\"{0:.2f}\".format(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbr = dict(build_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbr = [[k] + v for k, v in sorted(tbr.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['diagramQuestions', '0.25'],\n",
       " ['nonDiagramQuestions', '0.33'],\n",
       " ['overall', '0.59']]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[['diagramQuestions', '0.25'], ['nonDiagramQuestions', '0.33'], ['overall', '0.59']], [['diagramQuestions', '3124.00'], ['nonDiagramQuestions', '4584.00'], ['overall', '7708.00']]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out_tuples.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-98-f84ea43341a5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-98-f84ea43341a5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    flattened_list = [item for sublist in for item in sublist]\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "flattened_list = [item for sublist in for item in sublist]\n",
    "flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+-----------------+\n",
      "| question type       |   accuracy |   total correct |\n",
      "+=====================+============+=================+\n",
      "| diagramQuestions    |       0.25 |            3124 |\n",
      "+---------------------+------------+-----------------+\n",
      "| nonDiagramQuestions |       0.33 |            4584 |\n",
      "+---------------------+------------+-----------------+\n",
      "| overall             |       0.59 |            7708 |\n",
      "+---------------------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(tbr, ['question type'] + list(test_out_tuples.keys()), tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diagramQuestions', 'nonDiagramQuestions', 'overall_accuracy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All validation test pass\n",
      "{'diagramQuestions': 0.24858757062146894, 'nonDiagramQuestions': 0.33476959030161396, 'overall_accuracy': 0.2935262757044935}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'diagramQuestions': 0.24858757062146894,\n",
       " 'nonDiagramQuestions': 0.33476959030161396,\n",
       " 'overall_accuracy': 0.2935262757044935}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_student_results = evaluator.evaluate_model(bad_student_answers)\n",
    "bad_student_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "| column 1   | column 2   |\n",
      "+============+============+\n",
      "| value1     | value2     |\n",
      "+------------+------------+\n",
      "| value3     | value4     |\n",
      "+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[\"value1\", \"value2\"], [\"value3\", \"value4\"]], [\"column 1\", \"column 2\"], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cheating_student_answers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2e41d8c1844d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheater_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheating_student_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cheating_student_answers' is not defined"
     ]
    }
   ],
   "source": [
    "cheater_results = evaluator.evaluate_model(cheating_student_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-90fbd517ef6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_question_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mboth_qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_question_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluator' is not defined"
     ]
    }
   ],
   "source": [
    "all_qs = evaluator.build_question_lookup()\n",
    "both_qs = evaluator.build_question_lookup(by_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for qid, question in ndqs.items():\n",
    "#     print(question['questionType'])\n",
    "\n",
    "def dict_key_extract(key, var):\n",
    "    if hasattr(var, 'items'):\n",
    "        for k, v in var.items():\n",
    "            if k == key:\n",
    "                yield v\n",
    "            if isinstance(v, dict):\n",
    "                for result in dict_key_extract(key, v):\n",
    "                    yield result\n",
    "            elif isinstance(v, list):\n",
    "                for d in v:\n",
    "                    for result in dict_key_extract(key, d):\n",
    "                        yield result\n",
    "\n",
    "new_w_dw_complete_flat_ds_kc_all_fix = bad_student.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "non_diagram_questions = [list(dict_key_extract('nonDiagramQuestions', lesson)) for lesson in new_w_dw_complete_flat_ds_kc_all_fix]\n",
    "\n",
    "nd_questions = {}\n",
    "for lesson in non_diagram_questions:\n",
    "    for lesson_questions in lesson:\n",
    "        for question_id, question in lesson_questions.items():\n",
    "            nd_questions[question_id] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nd_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "missing_ac = []\n",
    "for qid, question in nd_questions.items():\n",
    "    if question['questionType'] == 'Multiple Choice' and not question['answerChoices']:\n",
    "        missing_ac.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
